{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6UZPQpkdQv33",
        "outputId": "fa5a290e-def9-41c2-c90e-db44d16ee1ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.37)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.108)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.15 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.15)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.37 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.37)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.108)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.15->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.15->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.37->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.37->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.37->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.37->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain_community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.3.1\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.10)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.33 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.2.37)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.64.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (0.1.108)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.20.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.33->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (3.10.7)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install faiss-cpu\n",
        "!pip install pypdf\n",
        "!pip install google-generativeai langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# procees the pdf"
      ],
      "metadata": {
        "id": "hsvcCgpMWZP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def process_dic(dic):\n",
        "    loader = PyPDFDirectoryLoader(dic)\n",
        "    data = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=20)\n",
        "    text_chunks = text_splitter.split_documents(data)\n",
        "    chunk_texts = [chunk.page_content for chunk in text_chunks]\n",
        "    return  chunk_texts\n"
      ],
      "metadata": {
        "id": "Owjj5xgwvfYu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, chunk_size=2000):\n",
        "    \"\"\"Split the text into chunks of a maximum size.\"\"\"\n",
        "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "0exEAjvtzcMB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extract necessare info from resume"
      ],
      "metadata": {
        "id": "NEwcVL6aWTH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "text_chunks = process_dic(\"resums\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=\"AIzaSyAz4mqqTvqCJ49E7Xv7tuvku-w68kVhjxk\")\n",
        "template = \"\"\"\n",
        "Given the following resume text, extract key details including:\n",
        "1. Name\n",
        "2. Profile\n",
        "3. Contact Information\n",
        "4. Education\n",
        "5. Work Experience\n",
        "6. Projects\n",
        "7. Skills\n",
        "8. Certification\n",
        "\n",
        "Resume Text:\n",
        "{resume_text}\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"resume_text\"], template=template\n",
        ")\n",
        "resume_text = \"\\n\".join(text_chunks)\n",
        "prompt1 = prompt_template.format(resume_text=resume_text)\n",
        "output = llm.invoke(prompt1)\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIVnBvuevg6I",
        "outputId": "dc6bbc48-cb2d-4270-fb09-56b79e949045"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. **Name:** IBTISSAM ECH CHAIBI\n",
            "2. **Profile:** Seeking a summer internship in data science.\n",
            "3. **Contact Information:**\n",
            "   - Phone: 0610233997\n",
            "   - Email: btissamchaibi1912@gmail.com\n",
            "   - Address: Casablanca\n",
            "4. **Education:**\n",
            "   - National Higher School of Electricity and Mechanics (ENSEM), September 2022 - Jun 2025\n",
            "     - Engineer degree in software engineering and digitalization\n",
            "   - Preparatory classes for major engineering schools, September 2020 - Jun 2022\n",
            "     - Diploma in Mathematics and Physics\n",
            "   - Baccalaureate of Mathematical Sciences, September 2019 - June 2020\n",
            "     - Baccalaureate degree with mention very good\n",
            "5. **Work Experience:**\n",
            "   - Internship in digital sky start up, Jun 2023- July 2023\n",
            "     - Built an admin panel that assigns projects to startup workers using the MERN stack technology.\n",
            "6. **Projects:**\n",
            "   - Stock Data Extraction and Visualization\n",
            "     - Gathered financial data from Tesla, Amazon, AMD, and GameStop stocks and visualized trends in a dashboard.\n",
            "   - Rainfall Prediction Classifier\n",
            "     - Developed a machine learning model to predict next-day rainfall using Australian Bureau of Meteorology data.\n",
            "   - House Sales in King County, USA\n",
            "     - Analyzed residential property data to predict prices using linear regression and Ridge regression.\n",
            "   - Chicago Dataset Analysis and SQL Querying\n",
            "     - Analyzed three Chicago datasets using Python and executed SQL queries for insights.\n",
            "7. **Skills:**\n",
            "   - Programming: Python (Pandas, NumPy, Matplotlib, Scikit-learn), C++, Node.js, Java\n",
            "   - Machine Learning: Linear regression, KNN, Decision Trees, logistic regression, k-means clustering\n",
            "   - Databases: SQLite, MySQL, Mongodb (NoSQL)\n",
            "   - Tools: Git, Docker, VSCode, Jupyter Notebook\n",
            "8. **Certification:**\n",
            "   - Python for Data Science, AI Development (Coursera)\n",
            "   - Databases and SQL for Data Science with Python (Coursera)\n",
            "   - Data Analysis with Python (Coursera)\n",
            "   - Machine Learning with Python (Coursera)\n",
            "   - AI Career Essentials (ALX AiCE)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "goBBb0FRE0D5",
        "outputId": "f6b9ee6e-e351-4a4e-91ec-453de920e261"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. **Name:** IBTISSAM ECH CHAIBI\\n2. **Profile:** Seeking a summer internship in data science.\\n3. **Contact Information:**\\n   - Phone: 0610233997\\n   - Email: btissamchaibi1912@gmail.com\\n   - Address: Casablanca\\n4. **Education:**\\n   - National Higher School of Electricity and Mechanics (ENSEM), September 2022 - Jun 2025\\n     - Engineer degree in software engineering and digitalization\\n   - Preparatory classes for major engineering schools, September 2020 - Jun 2022\\n     - Diploma in Mathematics and Physics\\n   - Baccalaureate of Mathematical Sciences, September 2019 - June 2020\\n     - Baccalaureate degree with mention very good\\n5. **Work Experience:**\\n   - Internship in digital sky start up, Jun 2023- July 2023\\n     - Built an admin panel that assigns projects to startup workers using the MERN stack technology.\\n6. **Projects:**\\n   - Stock Data Extraction and Visualization\\n     - Gathered financial data from Tesla, Amazon, AMD, and GameStop stocks and visualized trends in a dashboard.\\n   - Rainfall Prediction Classifier\\n     - Developed a machine learning model to predict next-day rainfall using Australian Bureau of Meteorology data.\\n   - House Sales in King County, USA\\n     - Analyzed residential property data to predict prices using linear regression and Ridge regression.\\n   - Chicago Dataset Analysis and SQL Querying\\n     - Analyzed three Chicago datasets using Python and executed SQL queries for insights.\\n7. **Skills:**\\n   - Programming: Python (Pandas, NumPy, Matplotlib, Scikit-learn), C++, Node.js, Java\\n   - Machine Learning: Linear regression, KNN, Decision Trees, logistic regression, k-means clustering\\n   - Databases: SQLite, MySQL, Mongodb (NoSQL)\\n   - Tools: Git, Docker, VSCode, Jupyter Notebook\\n8. **Certification:**\\n   - Python for Data Science, AI Development (Coursera)\\n   - Databases and SQL for Data Science with Python (Coursera)\\n   - Data Analysis with Python (Coursera)\\n   - Machine Learning with Python (Coursera)\\n   - AI Career Essentials (ALX AiCE)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# format the output"
      ],
      "metadata": {
        "id": "i5KMa_15WeEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Example output from the LLM (replace this with actual output)\n",
        "output_content = output.content\n",
        "\n",
        "# Define headers\n",
        "headers = [\n",
        "    \"Name\", \"Profile\", \"Contact Information\", \"Education\", \"Work Experience\",\n",
        "    \"Projects\", \"Skills\", \"Certification\"\n",
        "]\n",
        "\n",
        "# Initialize a dictionary to hold the extracted information\n",
        "extracted_info = {}\n",
        "\n",
        "# Extract each section based on headers\n",
        "for header in headers:\n",
        "    # Adjust regex pattern based on actual content\n",
        "    # This pattern looks for the header followed by any characters until the next header or the end of text\n",
        "    pattern = rf\"\\d+\\.\\s+\\*\\*{re.escape(header)}:\\*\\*(.*?)(?=\\n\\d+\\.\\s+\\*\\*|\\Z)\"\n",
        "    match = re.search(pattern, output_content, re.DOTALL)\n",
        "    if match:\n",
        "        extracted_info[header] = match.group(1).strip()\n",
        "    else:\n",
        "        extracted_info[header] = \"Not found\"\n",
        "\n",
        "# Print the extracted information\n",
        "for section, content in extracted_info.items():\n",
        "    print(f\"{section}:\\n{content}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1rx9KvzDQM3",
        "outputId": "fe9fd82c-37ed-4ad9-f1bd-47c2bb4f38f1"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:\n",
            "IBTISSAM ECH CHAIBI\n",
            "\n",
            "Profile:\n",
            "Seeking a summer internship in data science.\n",
            "\n",
            "Contact Information:\n",
            "- Phone: 0610233997\n",
            "   - Email: btissamchaibi1912@gmail.com\n",
            "   - Address: Casablanca\n",
            "\n",
            "Education:\n",
            "- National Higher School of Electricity and Mechanics (ENSEM), September 2022 - Jun 2025\n",
            "     - Engineer degree in software engineering and digitalization\n",
            "   - Preparatory classes for major engineering schools, September 2020 - Jun 2022\n",
            "     - Diploma in Mathematics and Physics\n",
            "   - Baccalaureate of Mathematical Sciences, September 2019 - June 2020\n",
            "     - Baccalaureate degree with mention very good\n",
            "\n",
            "Work Experience:\n",
            "- Internship in digital sky start up, Jun 2023- July 2023\n",
            "     - Built an admin panel that assigns projects to startup workers using the MERN stack technology.\n",
            "\n",
            "Projects:\n",
            "- Stock Data Extraction and Visualization\n",
            "     - Gathered financial data from Tesla, Amazon, AMD, and GameStop stocks and visualized trends in a dashboard.\n",
            "   - Rainfall Prediction Classifier\n",
            "     - Developed a machine learning model to predict next-day rainfall using Australian Bureau of Meteorology data.\n",
            "   - House Sales in King County, USA\n",
            "     - Analyzed residential property data to predict prices using linear regression and Ridge regression.\n",
            "   - Chicago Dataset Analysis and SQL Querying\n",
            "     - Analyzed three Chicago datasets using Python and executed SQL queries for insights.\n",
            "\n",
            "Skills:\n",
            "- Programming: Python (Pandas, NumPy, Matplotlib, Scikit-learn), C++, Node.js, Java\n",
            "   - Machine Learning: Linear regression, KNN, Decision Trees, logistic regression, k-means clustering\n",
            "   - Databases: SQLite, MySQL, Mongodb (NoSQL)\n",
            "   - Tools: Git, Docker, VSCode, Jupyter Notebook\n",
            "\n",
            "Certification:\n",
            "- Python for Data Science, AI Development (Coursera)\n",
            "   - Databases and SQL for Data Science with Python (Coursera)\n",
            "   - Data Analysis with Python (Coursera)\n",
            "   - Machine Learning with Python (Coursera)\n",
            "   - AI Career Essentials (ALX AiCE)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeTzhxq8ysKW",
        "outputId": "676dd89e-747c-4207-add2-73313494f9b3"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Name': 'IBTISSAM ECH CHAIBI',\n",
              " 'Profile': 'Seeking a summer internship in data science.',\n",
              " 'Contact Information': '- Phone: 0610233997\\n   - Email: btissamchaibi1912@gmail.com\\n   - Address: Casablanca',\n",
              " 'Education': '- National Higher School of Electricity and Mechanics (ENSEM), September 2022 - Jun 2025\\n     - Engineer degree in software engineering and digitalization\\n   - Preparatory classes for major engineering schools, September 2020 - Jun 2022\\n     - Diploma in Mathematics and Physics\\n   - Baccalaureate of Mathematical Sciences, September 2019 - June 2020\\n     - Baccalaureate degree with mention very good',\n",
              " 'Work Experience': '- Internship in digital sky start up, Jun 2023- July 2023\\n     - Built an admin panel that assigns projects to startup workers using the MERN stack technology.',\n",
              " 'Projects': '- Stock Data Extraction and Visualization\\n     - Gathered financial data from Tesla, Amazon, AMD, and GameStop stocks and visualized trends in a dashboard.\\n   - Rainfall Prediction Classifier\\n     - Developed a machine learning model to predict next-day rainfall using Australian Bureau of Meteorology data.\\n   - House Sales in King County, USA\\n     - Analyzed residential property data to predict prices using linear regression and Ridge regression.\\n   - Chicago Dataset Analysis and SQL Querying\\n     - Analyzed three Chicago datasets using Python and executed SQL queries for insights.',\n",
              " 'Skills': '- Programming: Python (Pandas, NumPy, Matplotlib, Scikit-learn), C++, Node.js, Java\\n   - Machine Learning: Linear regression, KNN, Decision Trees, logistic regression, k-means clustering\\n   - Databases: SQLite, MySQL, Mongodb (NoSQL)\\n   - Tools: Git, Docker, VSCode, Jupyter Notebook',\n",
              " 'Certification': '- Python for Data Science, AI Development (Coursera)\\n   - Databases and SQL for Data Science with Python (Coursera)\\n   - Data Analysis with Python (Coursera)\\n   - Machine Learning with Python (Coursera)\\n   - AI Career Essentials (ALX AiCE)'}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_info['Skills']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "4E5vRAahUbNw",
        "outputId": "02f0bf97-91e4-4517-ae1c-bd201af411a2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'- Programming: Python (Pandas, NumPy, Matplotlib, Scikit-learn), C++, Node.js, Java\\n   - Machine Learning: Linear regression, KNN, Decision Trees, logistic regression, k-means clustering\\n   - Databases: SQLite, MySQL, Mongodb (NoSQL)\\n   - Tools: Git, Docker, VSCode, Jupyter Notebook'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate the interview questions"
      ],
      "metadata": {
        "id": "NuSdrGetWiA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_prompt_template = \"\"\"\n",
        "Based on the following extracted resume details, generate relevant interview questions:\n",
        "1. Profile : {Profile}\n",
        "2. Work Experience: {Work Experience}\n",
        "3. Projects: {Projects}\n",
        "4. Skills: {Skills}\n",
        "5. Certification: {Certification}\n",
        "\n",
        "Please generate insightful and relevant interview questions related to each section of the resume.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wZih5tg-IeCX"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the prompt with extracted information\n",
        "question_prompt = question_prompt_template.format(**extracted_info)\n",
        "\n",
        "# Invoke LLM to generate interview questions\n",
        "question_output = llm.invoke(question_prompt)\n",
        "\n",
        "# Print the generated interview questions\n",
        "print(\"Generated Interview Questions:\")\n",
        "print(question_output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVdOOLuPKJIE",
        "outputId": "23f0e8f5-cc6c-4346-a3a4-dad3da8b7dc6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Interview Questions:\n",
            "**Profile**\n",
            "\n",
            "* Why are you interested in a summer internship in data science?\n",
            "* What are your career aspirations in the field of data science?\n",
            "\n",
            "**Work Experience**\n",
            "\n",
            "* Describe the admin panel you built using the MERN stack technology.\n",
            "* How did you handle the challenges and what was the impact of your work on the startup?\n",
            "\n",
            "**Projects**\n",
            "\n",
            "* **Stock Data Extraction and Visualization:**\n",
            "    * How did you gather and clean the financial data from various sources?\n",
            "    * What insights did you derive from the data visualization?\n",
            "* **Rainfall Prediction Classifier:**\n",
            "    * Explain the machine learning model you developed and the data you used to train it.\n",
            "    * How did you evaluate the accuracy and robustness of your model?\n",
            "* **House Sales in King County, USA:**\n",
            "    * Describe the data analysis techniques you employed to predict property prices.\n",
            "    * What were the key factors influencing house prices and how did you incorporate them into your model?\n",
            "* **Chicago Dataset Analysis and SQL Querying:**\n",
            "    * What insights did you gain from analyzing the Chicago datasets?\n",
            "    * Provide examples of SQL queries you executed and how they helped you extract meaningful information.\n",
            "\n",
            "**Skills**\n",
            "\n",
            "* **Programming:**\n",
            "    * Demonstrate your proficiency in Python and its data science libraries (Pandas, NumPy, Matplotlib, Scikit-learn).\n",
            "    * Discuss your experience in other programming languages (C++, Node.js, Java).\n",
            "* **Machine Learning:**\n",
            "    * Explain the principles of linear regression, k-means clustering, and other machine learning algorithms.\n",
            "    * Describe how you apply these algorithms to real-world data science problems.\n",
            "* **Databases:**\n",
            "    * Explain the differences between SQL and NoSQL databases.\n",
            "    * Discuss your experience using SQLite, MySQL, and Mongodb.\n",
            "* **Tools:**\n",
            "    * How do you use Git for version control and collaboration?\n",
            "    * Describe your experience with Docker for containerization.\n",
            "    * Explain how you utilize VSCode and Jupyter Notebook for data science tasks.\n",
            "\n",
            "**Certification**\n",
            "\n",
            "* **Python for Data Science, AI Development:**\n",
            "    * How did this certification enhance your data science skills?\n",
            "    * Discuss specific projects or applications where you applied the knowledge gained from this certification.\n",
            "* **Other Certifications:**\n",
            "    * How do the other certifications you hold complement your data science knowledge and abilities?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get awnser for spesific question"
      ],
      "metadata": {
        "id": "wFRs9XFnWmvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions_to_answer = [\n",
        "    \"Describe your proficiency in using Git for version control and collaboration\",\n",
        "    \"How has your certification in Python for Data Science enhanced your skills and knowledge?\"\n",
        "]\n",
        "\n",
        "# Function to get answers to specific questions\n",
        "def get_answers_to_questions(questions):\n",
        "    answers = []\n",
        "    for question in questions:\n",
        "        answer_prompt = f\"Please provide a detailed answer to the following question:\\n{question}\"\n",
        "        answer_output = llm.invoke(answer_prompt)\n",
        "        answers.append(answer_output.content)\n",
        "    return answers\n",
        "\n",
        "# Get answers to the specific questions\n",
        "answers = get_answers_to_questions(questions_to_answer)\n",
        "\n",
        "# Print the answers\n",
        "print(\"Answers to Specific Interview Questions:\")\n",
        "for question, answer in zip(questions_to_answer, answers):\n",
        "    print(f\"Q: {question}\")\n",
        "    print(f\"A: {answer}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwWWIyIcKioQ",
        "outputId": "7a18d904-a028-4d59-c509-27e2633367f6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answers to Specific Interview Questions:\n",
            "Q: Describe your proficiency in using Git for version control and collaboration\n",
            "A: **Proficiency in Git for Version Control and Collaboration**\n",
            "\n",
            "**Core Concepts:**\n",
            "\n",
            "* **Version Control:** Understanding the principles of version control, including tracking changes, branching, and merging.\n",
            "* **Centralized vs. Distributed:** Familiarity with both centralized (e.g., SVN) and distributed (e.g., Git) version control systems.\n",
            "* **Git Workflow:** Expertise in the fundamental Git workflow, including staging, committing, pushing, and pulling changes.\n",
            "\n",
            "**Command-Line Proficiency:**\n",
            "\n",
            "* **Basic Commands:** Mastery of essential Git commands, such as `git init`, `git add`, `git commit`, `git push`, and `git pull`.\n",
            "* **Branching and Merging:** Proficiency in creating, switching between, and merging branches using commands like `git branch`, `git checkout`, and `git merge`.\n",
            "* **Staging and Committing:** Understanding the difference between staging and committing changes, and the use of `git add` and `git commit` commands.\n",
            "\n",
            "**Collaboration and Team Workflow:**\n",
            "\n",
            "* **Pull Requests:** Expertise in creating, reviewing, and merging pull requests to collaborate with team members.\n",
            "* **Conflict Resolution:** Knowledge of common conflict scenarios and strategies for resolving them using `git mergetool`, `git rebase`, or manual conflict resolution.\n",
            "* **Code Review and Feedback:** Proficiency in using Git for code review and providing constructive feedback to team members.\n",
            "\n",
            "**Advanced Features:**\n",
            "\n",
            "* **Rebasing:** Understanding and applying rebasing techniques to reorganize commit history.\n",
            "* **Stashing:** Familiarity with the `git stash` command for temporarily shelving changes.\n",
            "* **Submodules:** Experience in using Git submodules to manage dependencies in larger projects.\n",
            "\n",
            "**Tools and Integrations:**\n",
            "\n",
            "* **Git GUI:** Proficiency in using Git graphical user interfaces (GUIs) for a more user-friendly experience.\n",
            "* **CI/CD Integration:** Knowledge of integrating Git with continuous integration and continuous delivery (CI/CD) pipelines.\n",
            "* **Project Management Tools:** Experience in using Git in conjunction with project management tools like Jira or Asana.\n",
            "\n",
            "**Additional Skills:**\n",
            "\n",
            "* **Version Control Best Practices:** Adherence to best practices for effective version control, such as using meaningful commit messages and following a consistent branching strategy.\n",
            "* **Communication and Collaboration:** Strong communication and collaboration skills for effective teamwork and conflict resolution.\n",
            "* **Problem-Solving:** Ability to identify and resolve common version control issues independently.\n",
            "\n",
            "Q: How has your certification in Python for Data Science enhanced your skills and knowledge?\n",
            "A: **Enhanced Skills and Knowledge Gained from Python for Data Science Certification:**\n",
            "\n",
            "**1. Data Analysis and Visualization:**\n",
            "- Deep understanding of data structures, data manipulation, and data visualization libraries like NumPy, Pandas, and Matplotlib.\n",
            "- Proficiency in data cleaning, exploratory data analysis, and creating informative visualizations to uncover patterns and insights.\n",
            "\n",
            "**2. Machine Learning and Modeling:**\n",
            "- Comprehensive knowledge of machine learning algorithms, such as supervised (linear regression, decision trees, support vector machines) and unsupervised (clustering, dimensionality reduction) techniques.\n",
            "- Practical experience in model building, training, evaluation, and hyperparameter tuning.\n",
            "\n",
            "**3. Data Science Workflow:**\n",
            "- Familiarity with the entire data science workflow, from data acquisition and preparation to model deployment.\n",
            "- Understanding of best practices for data preprocessing, feature engineering, and model evaluation.\n",
            "\n",
            "**4. Programming Proficiency:**\n",
            "- Enhanced Python programming skills, including object-oriented programming, data structures, and algorithms.\n",
            "- Improved ability to write efficient and maintainable code for data analysis and machine learning tasks.\n",
            "\n",
            "**5. Industry-Specific Knowledge:**\n",
            "- Exposure to real-world data science applications and industry-specific best practices.\n",
            "- Understanding of how Python is used in various domains, such as healthcare, finance, and e-commerce.\n",
            "\n",
            "**6. Communication and Collaboration:**\n",
            "- Developed skills in presenting data science findings effectively to stakeholders.\n",
            "- Enhanced ability to collaborate with other data scientists and domain experts to solve complex problems.\n",
            "\n",
            "**7. Problem-Solving and Critical Thinking:**\n",
            "- Improved analytical and problem-solving abilities through hands-on experience with data science projects.\n",
            "- Developed critical thinking skills in identifying the right data science tools and techniques for specific problems.\n",
            "\n",
            "**8. Career Advancement:**\n",
            "- Certification validates proficiency in Python for Data Science, making candidates more competitive in the job market.\n",
            "- Demonstrates a commitment to professional development and staying up-to-date with industry trends.\n",
            "\n",
            "**Overall Impact:**\n",
            "\n",
            "The Python for Data Science certification has provided a comprehensive foundation in essential data science skills and knowledge. It has enhanced my abilities in data analysis, machine learning, programming, and communication. This certification has been invaluable in my career advancement and has enabled me to make significant contributions to data-driven decision-making and problem-solving within my organization.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# match your profile with a job description"
      ],
      "metadata": {
        "id": "R3ltT5fcWrhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobs_match=\"\"\"\n",
        "Hey Act Like a skilled or very experience ATS(Application Tracking System)\n",
        "with a deep understanding of tech field,software engineering,data science ,data analyst\n",
        "and big data engineer. Your task is to evaluate the resume based on the given job description.\n",
        "You must consider the job market is very competitive and you should provide\n",
        "best assistance for improving thr resumes. Assign the percentage Matching based\n",
        "on Jd and\n",
        "the missing keywords with high accuracy\n",
        "Resume Details:\n",
        "{resume_details}\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "I want the response in one single string having the structure\n",
        "{{\"JD Match\":\"%\",\"MissingKeywords:[]\",\"Profile Summary\":\"\" , \"final decision\":\" \"}}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J3CtU4SFMMh0"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_details=\"\\n\".join([f\"{key}: {value}\" for key, value in extracted_info.items()])\n",
        "job_description=job_description = \"\"\"\n",
        "**Job Overview:**\n",
        "We are seeking a talented and experienced Data Scientist to join our team. The ideal candidate will have a strong background in data analysis, statistical modeling, and machine learning. You will work closely with our data engineering team and business stakeholders to develop predictive models, perform data mining, and generate actionable insights to support strategic decision-making.\n",
        "\n",
        "**Responsibilities:**\n",
        "\n",
        "- Analyze large datasets to uncover trends, patterns, and insights.\n",
        "- Develop and implement machine learning models and algorithms to solve complex business problems.\n",
        "- Create data visualizations and reports to present findings and recommendations to stakeholders.\n",
        "- Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions.\n",
        "- Optimize and improve existing data processes and models.\n",
        "- Stay current with industry trends and emerging technologies in data science and machine learning.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "- Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, Mathematics, or a related field.\n",
        "- Proven experience as a Data Scientist or similar role, with a strong portfolio of completed projects.\n",
        "- Proficiency in programming languages such as Python or R.\n",
        "- Experience with data manipulation and analysis tools (e.g., pandas, NumPy, scikit-learn).\n",
        "- Familiarity with big data technologies (e.g., Hadoop, Spark) is a plus.\n",
        "- Strong analytical and problem-solving skills, with the ability to work with complex datasets.\n",
        "- Excellent communication skills and the ability to present technical information to non-technical stakeholders.\n",
        "\n",
        "**Preferred Qualifications:**\n",
        "\n",
        "- Experience with cloud platforms (e.g., AWS, Azure, Google Cloud).\n",
        "- Knowledge of deep learning frameworks (e.g., TensorFlow, PyTorch).\n",
        "- Experience with SQL and relational databases.\n",
        "- Prior experience in a fast-paced, dynamic work environment.\n",
        "\n",
        "**Benefits:**\n",
        "\n",
        "- Competitive salary and performance-based bonuses.\n",
        "- Comprehensive health, dental, and vision insurance.\n",
        "- 401(k) plan with company match.\n",
        "- Generous paid time off and holidays.\n",
        "- Opportunities for professional development and career growth.\n",
        "- A collaborative and innovative work environment.\n",
        "\n",
        "**How to Apply:**\n",
        "\n",
        "Interested candidates should submit their resume and a cover letter detailing their experience and qualifications for the role. Please send your application to careers@datainnovators.com with the subject line “Data Scientist Application – [Your Name].”\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "GOaETSyIPbTc"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_prompt = jobs_match.format(\n",
        "    job_description=job_description,\n",
        "    resume_details= resume_details\n",
        ")\n",
        "\n",
        "# Invoke LLM to perform the comparison\n",
        "comparison_output = llm.invoke(comparison_prompt)\n",
        "\n",
        "# Print the comparison results\n",
        "print(\"Comparison Results:\")\n",
        "print(comparison_output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5hB_w0PUTM",
        "outputId": "cf7e778a-055e-49df-9da3-589028ac7c94"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison Results:\n",
            "{\"JD Match\":\"60%\",\"MissingKeywords\":[\"Hadoop\",\"Spark\",\"Deep learning frameworks\",\"Cloud platforms (e.g., AWS, Azure, Google Cloud)\"],\"Profile Summary\":\"Ibttissam Ech Chaibi is a data science enthusiast seeking a summer internship. She is pursuing an engineer degree in software engineering and digitalization from the National Higher School of Electricity and Mechanics (ENSEM). With her strong academic background in mathematics, physics, and computer science, she has developed a solid foundation in data analysis, machine learning, and programming languages. Her work experience at Digital Sky Start Up, where she built an admin panel using the MERN stack technology, demonstrates her practical skills in data management and web development. Ibttissam's projects, such as stock data extraction and visualization, rainfall prediction, and house sales analysis, showcase her ability to apply data science techniques to solve real-world problems. Her proficiency in Python, C++, Node.js, and Java, along with her familiarity with databases like SQLite, MySQL, and MongoDB, makes her a versatile candidate. Ibttissam's certifications in Python for Data Science, AI Development, Databases and SQL for Data Science, Data Analysis with Python, and Machine Learning with Python, further validate her knowledge and commitment to the field. To improve her resume, Ibttissam should highlight her experience with big data technologies like Hadoop and Spark, as well as her knowledge of deep learning frameworks. Including specific examples of her work in these areas would strengthen her application. Additionally, mentioning any experience with cloud platforms like AWS or Azure would further align her resume with the job description. Overall, Ibttissam's resume demonstrates her potential as a data scientist. With some additional enhancements, she can effectively showcase her skills and increase her chances of securing a summer internship in data science.\",\"final decision\":\"Shortlist\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# search for real time oportinuties based on your skills and profile"
      ],
      "metadata": {
        "id": "JCwRvNbEWwLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  google-search-results langchain-community"
      ],
      "metadata": {
        "id": "BHuiIoBqtNgZ"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain_community.tools.google_jobs import GoogleJobsQueryRun\n",
        "from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper\n",
        "\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"dfb620d599c6a56f50d33bac58238613c68658266d617a2506226273b1f1385e\"\n",
        "tool = GoogleJobsQueryRun(api_wrapper=GoogleJobsAPIWrapper())\n",
        "tool.run(\"Can I get an entry level job posting related to physics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "qSE8YLCxI95M",
        "outputId": "7b5df2e5-5730-4914-8b7d-1a3c04316412"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n_______________________________________________\\nJob Title: Physicist / Applied Physicist - Entry Level\\nCompany Name: MIT Lincoln Laboratory\\nLocation: Lexington, MA\\nDescription: The Quantum Information and Integrated Nanosystems Group at MIT Lincoln Laboratory develops quantum systems, including theory, engineering, and control, to address critical future technology needs. Areas of focus include developing superconducting qubits for quantum computing, trapped ions for quantum information and precision time keeping, integrated photonics, and solid-state quantum sensing. The group’s innovative research is supported by on-site state-of-the-art fabrication tools, close partnership with universities and industry, extensive test and measurement infrastructure, and daily collaboration with the 1700+ Ph.D-level scientists within Lincoln Laboratory.\\n\\nJob Description\\n\\nMIT Lincoln Laboratory seeks a highly motivated, detail-oriented, curious and driven physicist, applied physicist, or researcher in a related field with hands-on lab experience. The successful candidate will join a close-knit, dynamic team pushing the forefront of quantum information processing and precision time keeping using trapped ions. As an active participant in cutting-edge research and development, the candidate can expect to face novel physics problems that require creative solutions on a daily basis.\\n\\nJob Description\\n\\nApplicants should have a broad skillset and a willingness to work on a wide variety of tasks as needed. Typical tasks are:\\n\\n• Test and measurement of laboratory systems, including lasers, optics, electronics, cryogenics, vacuum\\n\\n• Programming for experimental control and data analysis\\n\\n• Fundamental physics modelling of quantum systems\\n\\n• Hardware development, design, and construction\\n\\n• System engineering and system integration\\n\\nWhile a broad set of skills is desired, the majority of day-to-day tasks will be tailored to the applicant's specific interests and strengths. Applicants should be comfortable both working alone in a self-directed manner and also working closely with a highly-integrated larger team.\\n\\nRequirements\\n• Bachelor’s degree in Physics, Applied Physics, or related field\\n• Basic laboratory experience (e.g., familiarity with optics, oscilloscopes, basic programming, etc.)\\n• Comfort with fundamental physical concepts and rigorous analytical analysis\\n• Experience in self-directed and group technical projects and research endeavors\\n• Experience with a scientific programming language, such as MATLAB, Mathematica, Python, etc.\\n\\nPreferred Experience\\n• Experience with free-space and fiber optics, lasers, etc.\\n• Familiarity with ultra-high vacuum and cryogenics\\n• General-purpose programming (e.g., Python)\\n• CAD design (e.g. SolidWorks)\\n\\nFamiliarity with experimental quantum, atomic, or molecular physics is not required but is a plus\\n\\nAt MIT Lincoln Laboratory, our exceptional career opportunities include many outstanding benefits to help you stay healthy, feel supported, and enjoy a fulfilling work-life balance. Benefits offered to employees include:\\n• Comprehensive health, dental, and vision plans\\n• MIT-funded pension\\n• Matching 401K\\n• Paid leave (including vacation, sick, parental, military, etc.)\\n• Tuition reimbursement and continuing education programs\\n• Mentorship programs\\n• A range of work-life balance options\\n• ... and much more!\\n\\nPlease visit our Benefits page for more information. As an employee of MIT, you can also take advantage of other voluntary benefits, discounts and perks.\\n\\nSelected candidate will be subject to a pre-employment background investigation and must be able to obtain and maintain a Secret level DoD security clearance.\\n\\nMIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, or genetic information; U.S. citizenship is required.\\n\\nRequisition ID: 40774\\n_______________________________________________\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jobs_search=\"\"\"\n",
        "can you give me real time oportonitis that can aligne with this profile skiils and profile\n",
        "{profile}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jwBEo_XHhjTO"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['SERPAPI_API_KEY'] = 'dfb620d599c6a56f50d33bac58238613c68658266d617a2506226273b1f1385e'"
      ],
      "metadata": {
        "id": "D35ZRzYagy9x"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from serpapi import GoogleSearch\n",
        "profile = extracted_info['Profile']\n",
        "search_prompt = jobs_search.format(profile=profile)\n",
        "tools = load_tools([\"google-jobs\"], llm=llm)\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "result = agent.run(search_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RwM5XXub40fz",
        "outputId": "54d89980-f800-4774-cec7-f0a9e0ca48bb"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m you should always consider using google_jobs to find real-time opportunities.\n",
            "Action: google_jobs\n",
            "Action Input: \"summer internship data science\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "_______________________________________________\n",
            "Job Title: Campus Graduate - 2025 Data Science Finance Summer Internship New York, NY\n",
            "Company Name: American Express\n",
            "Location: New York, NY\n",
            "Description: American Express leverages Machine Learning and Artificial Intelligence to enhance predictions and provide actionable insights that guide decision-making. The role involves developing sophisticated models and analytical tools that influence the company's strategies related to financial metrics, credit fraud, and overall balance sheet management. Additionally, the team focuses on using data-driven approaches to address business challenges and opportunities. This collaborative environment encourages intellectual curiosity and problem-solving to drive meaningful impacts for the organization and its card members.\n",
            "_______________________________________________\n",
            "\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This looks like a great opportunity for someone with data science skills!\n",
            "Action: google_jobs\n",
            "Action Input: \"data science skills internship\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "_______________________________________________\n",
            "Job Title: Data Science Internship\n",
            "Company Name: T-Mobile\n",
            "Location: Overland Park, KS\n",
            "Description: Are you a curious and driven individual with a passion for data analysis and problem-solving? Look no further! T-Mobile is seeking a Data Science Intern to join our dynamic team and gain hands-on experience in the world of data-driven decision making. In this role, you will have the opportunity to work alongside experienced data scientists and make a meaningful impact on the future of our company. We are looking for a motivated and detail-oriented individual with strong analytical skills and a desire to learn. If you are ready to take your data science skills to the next level, we want to hear from you!\n",
            "\n",
            "Conduct data analysis and provide insights to support decision-making processes.\n",
            "Work closely with experienced data scientists to learn and apply data science techniques and methodologies.\n",
            "Collaborate with cross-functional teams to identify business problems and develop solutions using data.\n",
            "Perform data cleaning, manipulation, and visualization to prepare data for analysis.\n",
            "Utilize statistical modeling and machine learning techniques to extract meaningful insights from data.\n",
            "Communicate findings and recommendations to stakeholders in a clear and concise manner.\n",
            "Continuously learn and stay updated on new data science techniques and tools.\n",
            "Assist in developing and maintaining data science workflows and processes.\n",
            "Participate in team meetings and contribute ideas for improving data analysis processes.\n",
            "Adhere to data privacy and security policies and procedures.\n",
            "Take ownership of assigned projects and deliver results within specified timelines.\n",
            "Document and maintain accurate records of data analysis processes and methodologies.\n",
            "Collaborate with other interns and team members to support each other's learning and development.\n",
            "Demonstrate a strong work ethic and willingness to learn and adapt in a fast-paced environment.\n",
            "Contribute to a positive and collaborative team culture at T-Mobile.\n",
            "\n",
            "T-Mobile is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.\n",
            "_______________________________________________\n",
            "\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This internship also offers the opportunity to work with experienced data scientists and learn new techniques.\n",
            "Action: google_jobs\n",
            "Action Input: \"data science internship experience\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "_______________________________________________\n",
            "Job Title: Data Scientist - Internship Program 2025\n",
            "Company Name: 84.51° University Programs / Early Career Paths\n",
            "Location: Cincinnati, OH\n",
            "Description: 84.51°\n",
            "\n",
            "Data Scientist - Intern Program\n",
            "\n",
            "Location Option(s): Cincinnati, OH & Chicago, ILProgram Duration: May 27, 2025 - August 1, 2025\n",
            "\n",
            "This program requires you to be in the office 40 hours a week; there are no remote options.\n",
            "\n",
            "SUMMARY:\n",
            "\n",
            "As data scientists, we are a connected community of practice that enables the business teams with which we collaborate to understand the Kroger customer and act on their behalf. We bring an integrated, 360° view of our customer, allowing us to anticipate their needs, enable better business decisions, and make peoples' lives easier. As a result, we grow loyalty to Kroger and CPG brands.\n",
            "\n",
            "The Data Scientist Internship is a 10-week, full-time paid intern position that will allow you to gain work experience and learn about 84.51°- what we do and how we do it. This exciting program gives you the opportunity to participate in a learning experience where you will work collaboratively with 84.51° employees to complete a challenging live project that adds value to our business. It also gives you the opportunity to build strong bonds with all the other Interns as well as network with our 84.51° community.\n",
            "\n",
            "INTERN PROGRAM:\n",
            "\n",
            "The Intern Program duration is strictly the dates outlined at the top (interns cannot start or end early or late). Data Science roles are open in our Cincinnati, OH Headquarters office and our downtown Chicago, IL office (Old Post Office). Interns are matched with a manager and mentor, both Data Scientists, to support them during the program. Interns should expect to work in the office Monday-Friday, 40 hours per week, typically between 8am-5pm. Specific team norms around working hours will be communicated by your manager upon starting. Interns should not have conflicts such as classes or other employment during the 84.51° workday.\n",
            "\n",
            "84.51° is divided into two models made up of cross-functional teams: the Kroger model and the Commercial model. These models are named for their core stakeholders and priorities, and data scientists play a critical part in the success of these cross-functional teams. All Data Science interns will be given a project and be assigned to one of our specific Data Science groups aligned to one of our business teams.\n",
            "\n",
            "As a Data Science Intern, you are assigned to and embedded within one of our business teams. You will then leverage our vast amount of first party data to develop new methodologies and/or insights - allowing us to understand customers better than anyone else. Your internship project will enable our clients to have the right strategy and drive better execution for areas such as customer loyalty, pricing, promotions, assortment, new product innovation, digital media, local marketing, and direct-to-consumer communications.\n",
            "\n",
            "Upon completion of the 10-week internship, if we believe you met objectives while demonstrating our 84.51° values, you will be offered a position to join us full-time as part of 84.51°'s Development Program upon graduation (or offer another Internship if you have another summer before graduating).\n",
            "\n",
            "WHAT DATA SCIENCE MEANS TO US:\n",
            "\n",
            "All Data Scientists will join a community of learners, problem solvers, and collaborators. We hire Data Scientists with a variety of skillsets to align with the diverse body of analytical work across the business. A candidate's data science aptitudes will vary based on background and prior experience, bringing a unique set of skills to the table.\n",
            "\n",
            "Data Scientists at 84.51° are not \"one size fits all.\" There are common skills all Data Scientists possess which we teach and reenforce such as Python/PySpark, but we also value skills that run the gamut from storytelling to data munging to machine learning. Our definition of Data Science is robust, and you may have broad responsibilities ranging from building data pipelines, surfacing actionable insights for clients through applied analytics, and machine learning model creation and deployment. Some Data Science roles may incorporate all these skillsets while others may be more focused on insight generation or data curation instead of machine learning and statistical analysis. We value candidates who have a desire to build a breadth of experience across the 84.51° and Kroger businesses. As you develop your strengths over time, and hone your interests, various career paths become available to grow your career at 84.51°.\n",
            "\n",
            "QUALIFICATIONS, SKILLS, AND EXPERIENCE WE VALUE:\n",
            "• Working towards a bachelor's degree or higher from a four-year accredited university in Economics, Statistics, Mathematics, Computer Science, Market Research, Business Analytics, Information Systems, Data Science, or another heavily quantitative program. We also consider applicants from other degree fields given prior internship or project experience related to data science and analytics.\n",
            "• Graduating May/June 2027 or sooner - must be current student at time of internship\n",
            "• An interest in and experience writing efficient and scalable coding (Python, R, SQL, Spark, etc.). Our primary languages are PySpark and Python, though we value any coding experience you may have background in when applying\n",
            "• Familiarity with version control and/or process improvement and automation (GitHub)\n",
            "• Experience with data visualization, storytelling, and communicating with diverse business audiences\n",
            "• Familiarity with theory and application of multiple machine learning techniques (logistic regression, clustering, etc.) and statistical measurement capabilities (Test/Control Methodologies)\n",
            "• Strong business and commercial acumen with the ability to translate technical concepts for non-technical audiences and link analysis to business impact\n",
            "• Natural curiosity that welcomes and embraces change and willingness to try new things and to fail\n",
            "• Interest in working on teams with cross-functional partners such as consultants, engineering, and product owners\n",
            "\n",
            "#LI-DNI\n",
            "_______________________________________________\n",
            "\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This internship program also offers the opportunity to learn about 84.51° and gain valuable work experience.\n",
            "Action: google_jobs\n",
            "Action Input: \"84.51° data science internship\"\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'jobs_results'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-1f6246fd5689>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Initialize the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAgentType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZERO_SHOT_REACT_DESCRIPTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    599\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    379\u001b[0m         }\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             outputs = (\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1626\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent_action\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m             yield self._perform_agent_action(\n\u001b[0m\u001b[1;32m   1417\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1436\u001b[0m                 \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m             \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             observation = tool.run(\n\u001b[0m\u001b[1;32m   1439\u001b[0m                 \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig_param\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_get_runnable_config_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mtool_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"content_and_artifact\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/tools/google_jobs/tool.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     27\u001b[0m     ) -> str:\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m\"\"\"Use the tool.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/utilities/google_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtotal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserp_search_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mtotal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jobs_results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# extract 1 job info:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'jobs_results'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate a cover letter"
      ],
      "metadata": {
        "id": "1onJQb5HXaGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cover_letter = \"\"\"\n",
        "Please generate a detailed and well-structured cover letter for a job application based on the following information:\n",
        "\n",
        "1. **Resume Details:**\n",
        "   {resume_details}\n",
        "\n",
        "2. **Job Description:**\n",
        "   {job_description}\n",
        "\n",
        "The cover letter should:\n",
        "- Begin with a strong introduction that expresses enthusiasm for the position and the company.\n",
        "- Clearly outline relevant skills, experiences, and achievements from the resume that align with the job description.\n",
        "- Highlight specific projects, accomplishments, or qualifications that make the applicant a strong candidate for the role.\n",
        "- Include a professional and engaging narrative that demonstrates the applicant's suitability for the position.\n",
        "- Conclude with a compelling closing statement that reaffirms interest in the role and expresses a desire for further discussion.\n",
        "\n",
        "Ensure that the cover letter is personalized, specific to the job description, and long enough to cover all relevant aspects of the applicant's background and fit for the position.\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "dGmkit8aMLUN"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_details=\"\\n\".join([f\"{key}: {value}\" for key, value in extracted_info.items()])\n",
        "job_description=job_description = \"\"\"\n",
        "\n",
        "** company name : **\n",
        " 3D smart factory\n",
        "**Job Overview:**\n",
        "We are seeking a talented and experienced Data Scientist to join our team. The ideal candidate will have a strong background in data analysis, statistical modeling, and machine learning. You will work closely with our data engineering team and business stakeholders to develop predictive models, perform data mining, and generate actionable insights to support strategic decision-making.\n",
        "\n",
        "**Responsibilities:**\n",
        "\n",
        "- Analyze large datasets to uncover trends, patterns, and insights.\n",
        "- Develop and implement machine learning models and algorithms to solve complex business problems.\n",
        "- Create data visualizations and reports to present findings and recommendations to stakeholders.\n",
        "- Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions.\n",
        "- Optimize and improve existing data processes and models.\n",
        "- Stay current with industry trends and emerging technologies in data science and machine learning.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "- Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, Mathematics, or a related field.\n",
        "- Proven experience as a Data Scientist or similar role, with a strong portfolio of completed projects.\n",
        "- Proficiency in programming languages such as Python or R.\n",
        "- Experience with data manipulation and analysis tools (e.g., pandas, NumPy, scikit-learn).\n",
        "- Familiarity with big data technologies (e.g., Hadoop, Spark) is a plus.\n",
        "- Strong analytical and problem-solving skills, with the ability to work with complex datasets.\n",
        "- Excellent communication skills and the ability to present technical information to non-technical stakeholders.\n",
        "\n",
        "**Preferred Qualifications:**\n",
        "\n",
        "- Experience with cloud platforms (e.g., AWS, Azure, Google Cloud).\n",
        "- Knowledge of deep learning frameworks (e.g., TensorFlow, PyTorch).\n",
        "- Experience with SQL and relational databases.\n",
        "- Prior experience in a fast-paced, dynamic work environment.\n",
        "\n",
        "**Benefits:**\n",
        "\n",
        "- Competitive salary and performance-based bonuses.\n",
        "- Comprehensive health, dental, and vision insurance.\n",
        "- 401(k) plan with company match.\n",
        "- Generous paid time off and holidays.\n",
        "- Opportunities for professional development and career growth.\n",
        "- A collaborative and innovative work environment.\n",
        "\n",
        "**How to Apply:**\n",
        "\n",
        "Interested candidates should submit their resume and a cover letter detailing their experience and qualifications for the role. Please send your application to careers@datainnovators.com with the subject line “Data Scientist Application – [Your Name].”\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "IDdSuhiAX18Q"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cover_prompt = cover_letter.format(\n",
        "    job_description=job_description,\n",
        "    resume_details= resume_details\n",
        ")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=\"AIzaSyAz4mqqTvqCJ49E7Xv7tuvku-w68kVhjxk\")\n",
        "\n",
        "# Invoke LLM to perform the comparison\n",
        "cover_prompt_output = llm.invoke(cover_prompt)\n",
        "\n",
        "# Print the comparison results\n",
        "print(\"Cover letter :\")\n",
        "print(cover_prompt_output.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNbMOIIRYByC",
        "outputId": "caacfc1a-6817-4991-81ac-36396befd583"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cover letter :\n",
            "**[Your Name]**\n",
            "[Your Address]\n",
            "Casablanca, Morocco\n",
            "[Phone Number]\n",
            "[Email Address]\n",
            "\n",
            "[Date]\n",
            "\n",
            "3D Smart Factory\n",
            "[Company Address]\n",
            "[City, State, Zip Code]\n",
            "\n",
            "Dear Hiring Manager,\n",
            "\n",
            "I am writing to express my keen interest in the Data Science Internship position at 3D Smart Factory. With my strong foundation in data analysis, statistical modeling, and machine learning, I am confident that I possess the skills and experience necessary to excel in this role.\n",
            "\n",
            "As an aspiring Data Scientist, I have a deep understanding of data manipulation and analysis techniques using Python, Pandas, NumPy, and Scikit-learn. My experience in extracting insights from large datasets aligns perfectly with your company's need for uncovering trends and patterns. Furthermore, my proficiency in predictive modeling, including linear regression, KNN, and decision trees, enables me to develop robust solutions to complex business problems.\n",
            "\n",
            "During my internship at Digital Sky Start Up, I played a pivotal role in building an admin panel that effectively assigned projects to startup workers. This project not only showcased my technical abilities but also demonstrated my ability to work independently and deliver high-quality results.\n",
            "\n",
            "Moreover, my academic background in Software Engineering and Digitalization has equipped me with a solid understanding of software development principles and best practices. I am also proficient in various programming languages, including C++, Node.js, and Java, which allows me to seamlessly integrate data science solutions into software applications.\n",
            "\n",
            "I am particularly excited about the opportunity to contribute my skills to 3D Smart Factory's data-driven decision-making process. I am eager to leverage my analytical abilities to identify opportunities for optimization, improve existing models, and support the company's strategic initiatives.\n",
            "\n",
            "Furthermore, my strong communication skills and ability to present technical information clearly to non-technical stakeholders will enable me to effectively communicate my findings and recommendations. I am also a highly motivated and results-oriented individual with a strong work ethic and a commitment to continuous learning.\n",
            "\n",
            "I am confident that my skills and enthusiasm would make me a valuable asset to your team. I am eager to discuss my qualifications further and demonstrate how I can contribute to the success of 3D Smart Factory.\n",
            "\n",
            "Thank you for your time and consideration. I look forward to hearing from you soon.\n",
            "\n",
            "Sincerely,\n",
            "Ibtissam Ech Chaibi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#generate spesific advices"
      ],
      "metadata": {
        "id": "7HCdY8Edd1M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advice_template = \"\"\"\n",
        "Please provide detailed and actionable advice based on the following resume details:\n",
        "\n",
        "**Resume Details:**\n",
        "{resume_details}\n",
        "\n",
        "In your advice, please include the following:\n",
        "\n",
        "1. **Strengths:** Highlight the key strengths and skills evident from the resume. Explain how these strengths could be leveraged in a job search or career development.\n",
        "\n",
        "2. **Areas for Improvement:** Identify any gaps or areas where the resume could be improved. This might include skills, experience, or formatting suggestions.\n",
        "\n",
        "3. **Career Development Recommendations:** Offer specific recommendations for enhancing the resume or overall career prospects. This could involve additional skills to acquire, certifications to pursue, or types of experience to gain.\n",
        "\n",
        "4. **Tailoring for Specific Roles:** Provide advice on how to tailor the resume for specific types of roles or industries, if applicable. This might include emphasizing certain skills or experiences.\n",
        "\n",
        "5. **General Advice:** Include any other relevant advice for improving the resume or advancing in the chosen career path.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Q8tN3ix7YWpz"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_details=\"\\n\".join([f\"{key}: {value}\" for key, value in extracted_info.items()])"
      ],
      "metadata": {
        "id": "2YXI13POeaPH"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advice_template_prompt = advice_template.format(\n",
        "    resume_details= resume_details\n",
        ")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=\"AIzaSyAz4mqqTvqCJ49E7Xv7tuvku-w68kVhjxk\")\n",
        "\n",
        "# Invoke LLM to perform the comparison\n",
        "advice_template_prompt_output = llm.invoke(advice_template_prompt)\n",
        "\n",
        "# Print the comparison results\n",
        "print(\"advices :\")\n",
        "print(advice_template_prompt_output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnO698keea_6",
        "outputId": "8f27c255-0774-4893-c320-12f57cf7a330"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "advices :\n",
            "**1. Strengths:**\n",
            "\n",
            "* Strong programming skills in Python, C++, Node.js, and Java.\n",
            "* Proficiency in machine learning algorithms (linear regression, KNN, decision trees, etc.).\n",
            "* Experience with databases (SQLite, MySQL, MongoDB) and data analysis tools (Pandas, NumPy, Matplotlib).\n",
            "* Hands-on experience in building data science projects, including data extraction, visualization, and modeling.\n",
            "* Certifications in Python for Data Science, databases, and machine learning.\n",
            "\n",
            "These strengths demonstrate a solid foundation in data science fundamentals and the ability to apply these skills to practical projects.\n",
            "\n",
            "**2. Areas for Improvement:**\n",
            "\n",
            "* Lack of formal work experience in data science.\n",
            "* Limited experience in cloud computing or Big Data technologies.\n",
            "* Some formatting issues in the resume, such as inconsistent font sizes and spacing.\n",
            "\n",
            "**3. Career Development Recommendations:**\n",
            "\n",
            "* Seek internships or part-time roles in data science to gain practical experience.\n",
            "* Pursue additional certifications or online courses in cloud computing, Big Data, or specialized data science techniques.\n",
            "* Attend industry events and meetups to network with professionals and learn about new technologies.\n",
            "* Enhance the resume formatting for clarity and readability.\n",
            "\n",
            "**4. Tailoring for Specific Roles:**\n",
            "\n",
            "* For internships in large tech companies, emphasize skills in cloud computing, Big Data, and experience with specific frameworks (e.g., Hadoop, Spark).\n",
            "* For roles in healthcare or finance, highlight experience in relevant domains and knowledge of industry-specific data science applications.\n",
            "\n",
            "**5. General Advice:**\n",
            "\n",
            "* Quantify accomplishments whenever possible to demonstrate impact.\n",
            "* Use keywords relevant to the target roles in the resume and cover letter.\n",
            "* Seek feedback from mentors or industry professionals on the resume and overall career development plan.\n",
            "* Stay updated with the latest trends and technologies in data science by reading industry publications and attending conferences.\n",
            "* Consider pursuing a master's degree in data science or a related field for career advancement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tips and trics to get a spesific job"
      ],
      "metadata": {
        "id": "zSW06VhKfBiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips_template = \"\"\"\n",
        "Based on the following resume details and job description, please provide actionable tips and tricks to enhance the chances of securing the job.\n",
        "\n",
        "**Resume Details:**\n",
        "{resume_details}\n",
        "\n",
        "**Job Description:**\n",
        "{job_description}\n",
        "\n",
        "Please include the following in your advice:\n",
        "\n",
        "1. **Resume Optimization:** Suggest specific changes or improvements to the resume that would better align it with the job description.\n",
        "\n",
        "2. **Cover Letter Tips:** Provide guidance on tailoring a cover letter for this particular job. Mention key elements to include or emphasize.\n",
        "\n",
        "3. **Interview Preparation:** Offer tips on preparing for an interview for this role. This could involve common questions to anticipate, skills to highlight, or strategies for presenting oneself effectively.\n",
        "\n",
        "4. **Networking Strategies:** Advise on how to leverage networking to increase the chances of landing this job, such as connecting with industry professionals or using social media.\n",
        "\n",
        "5. **Skills and Experience:** Highlight any additional skills or experiences that could be beneficial for this role, including how to acquire or demonstrate them.\n",
        "\n",
        "6. **Application Strategy:** Provide recommendations on the overall application strategy, including any steps to follow up or additional materials to submit.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "YsiUvbK9eyEC"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tips_template_prompt = tips_template.format(\n",
        "    job_description=job_description,\n",
        "    resume_details= resume_details\n",
        "\n",
        ")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=\"AIzaSyAz4mqqTvqCJ49E7Xv7tuvku-w68kVhjxk\")\n",
        "\n",
        "# Invoke LLM to perform the comparison\n",
        "tips_template_prompt_output = llm.invoke(tips_template_prompt)\n",
        "\n",
        "# Print the comparison results\n",
        "print(\"tips  :\")\n",
        "print(tips_template_prompt_output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYVQsYKPffQs",
        "outputId": "90b7b340-3d9f-4358-8f8a-938ea65882f1"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tips  :\n",
            "**1. Resume Optimization:**\n",
            "\n",
            "- **Quantify work experience:** Provide specific metrics and results to demonstrate the impact of your projects and internship. For example, state the number of projects assigned or the accuracy of your rainfall prediction model.\n",
            "- **Highlight relevant skills:** Use keywords from the job description throughout your resume. For example, emphasize your proficiency in Python, machine learning algorithms, and data visualization tools.\n",
            "- **Showcase technical capabilities:** Include a section dedicated to your technical skills, using clear and concise language. List specific programming languages, data manipulation tools, and cloud platforms you are familiar with.\n",
            "- **Tailor to the job:** Review the job description carefully and identify the specific requirements and responsibilities. Adapt your resume to highlight the skills and experience that align most closely with the role.\n",
            "\n",
            "**2. Cover Letter Tips:**\n",
            "\n",
            "- **Grab attention:** Start your cover letter with a strong statement that summarizes your qualifications and why you are the ideal candidate for the role.\n",
            "- **Demonstrate alignment:** Clearly articulate how your skills and experience match the specific requirements outlined in the job description. Provide specific examples to support your claims.\n",
            "- **Highlight your passion:** Express your enthusiasm for data science and your desire to contribute to the company's success through data-driven insights.\n",
            "- **Proofread carefully:** Ensure your cover letter is well-written, error-free, and tailored to the specific job you are applying for.\n",
            "\n",
            "**3. Interview Preparation:**\n",
            "\n",
            "- **Anticipate common questions:** Research common interview questions for data scientists, such as those related to data analysis, machine learning, and problem-solving. Prepare thoughtful answers that showcase your knowledge and skills.\n",
            "- **Practice your presentation:** Rehearse presenting your skills and experience in a clear and engaging manner. Focus on highlighting your technical capabilities and how you can add value to the company.\n",
            "- **Demonstrate your problem-solving skills:** Be prepared to discuss real-world examples of how you have used data science to solve business problems. Emphasize your analytical and critical thinking abilities.\n",
            "\n",
            "**4. Networking Strategies:**\n",
            "\n",
            "- **Connect on LinkedIn:** Reach out to industry professionals on LinkedIn, including those working at the company you are applying to. Introduce yourself, express your interest in the role, and request informational interviews.\n",
            "- **Attend industry events:** Attend webinars, conferences, and meetups related to data science. This is an excellent opportunity to network with potential employers and learn about the latest industry trends.\n",
            "- **Engage on social media:** Follow companies and industry thought leaders on social media to stay informed about job opportunities and industry news. Participate in discussions and share relevant articles to demonstrate your expertise.\n",
            "\n",
            "**5. Skills and Experience:**\n",
            "\n",
            "- **Consider certifications:** Obtain certifications in data science or related fields to demonstrate your knowledge and commitment to professional development.\n",
            "- **Contribute to open-source projects:** Showcase your skills and gain real-world experience by contributing to open-source data science projects.\n",
            "- **Seek internships or freelance opportunities:** If you lack direct work experience as a data scientist, consider pursuing internships or freelance projects in the field.\n",
            "\n",
            "**6. Application Strategy:**\n",
            "\n",
            "- **Follow the instructions carefully:** Adhere to the application requirements provided in the job description, including submitting both a resume and a cover letter.\n",
            "- **Proofread before submitting:** Ensure your resume and cover letter are free of errors and present a polished and professional image.\n",
            "- **Follow up:** After submitting your application, consider sending a brief follow-up email to the hiring manager to express your continued interest and inquire about the status of your application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3T7Rc2nxf8XQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}